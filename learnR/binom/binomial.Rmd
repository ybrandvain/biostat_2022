---
title: "Tutorial"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(sortable)
library(tidyverse)
library(ggmosaic)
library(knitr)
library(broom)
knitr::opts_chunk$set(echo = FALSE)
```

# Binomial quiz

## Description and uncertainty 

### Background  

```{r, echo=FALSE,  out.width="40%"}
include_graphics("https://images.newscientist.com/wp-content/uploads/2017/06/02161911/d6c97k.jpg?crop=1:1,smart&width=1200&height=1200&upscale=true")
```

The Cook’s pine is native to New Caledonia, but has been planted as an ornamental across the world. They are notable for the way they lean to one side. When researchers looked into this, they found the 233 of the 256 trees they looked at leaned toward the equator. How weird is that? Lets find out.

### Estimation and uncertainty

Find the proportion of trees that leaned towards the equator, the variability in this sample (as the variance), and the uncertainty in this estimate (as the standard error)


Enter answer here...

```{r obs, echo = FALSE}
question_text("The variance in if Cook's pine trees lean to or away from the equator is (include three numbers past the decimal).",
 answer("0.082", correct = TRUE),
 answer(".082", correct = TRUE),
 answer("0.081", correct = TRUE),
 answer(".081", correct = TRUE),
 answer("0.0817", correct = TRUE),
 answer(".0817", correct = TRUE),
 answer("0.0818", correct = TRUE),
 answer(".0818", correct = TRUE),
 answer("0.08177", correct = TRUE),
 answer(".08177", correct = TRUE),
answer("0.08177185", correct = TRUE),
 answer(".08177185", correct = TRUE),
 allow_retry = TRUE,   
  correct = random_praise(),
  incorrect = random_encouragement()
)
```

Try a bootstrap as a way to estimate uncertainty in our estimate. We will later compare this to the equation R uses.

```{r bootbinom, exercise=TRUE, eval = FALSE}
tree_dat <- tibble(eq_or_not = rep(c("equator","not equator"),
                       times = c(233, __)))

many_boots <- replicate(n = 1000, simplify = FALSE,
          expr = slice_sample(tree_dat, prop = _, replace = TRUE)%>%
            summarise(prop_to_equator = mean(__ == "__")))%>%
  bind_rows()

many_boots %>%
  summarise(se = __(prop_to_equator),
            lower_95_CI = __(__, __),
            upper_95_CI = quantile(__, __))
```

```{r bootbinom-solution}
tree_dat <- tibble(eq_or_not = rep(c("equator","not equator"),
                       times = c(233, 23)))

many_boots <- replicate(n = 1000, simplify = FALSE,
          expr = slice_sample(tree_dat, prop = 1, replace = TRUE)%>%
            summarise(prop_to_equator = mean(eq_or_not == "equator")))%>%
  bind_rows()

many_boots %>%
  summarise(se = sd(prop_to_equator),
            lower_95_CI = quantile(prop_to_equator, 0.025),
            upper_95_CI = quantile(prop_to_equator, 0.975))
```




```{r compare, echo = FALSE}
question("Compared to the equation for the standard error, the bootstrap standard error is ___.",
 answer("Basically the same", correct = TRUE),
 answer("Obviously different, but not in a biologically relevant way"),
 answer("Way different, and not particularly useful"),
 allow_retry = TRUE,   
  correct = random_praise(),
  incorrect = random_encouragement()
)
```


```{r bootCI, echo = FALSE}
question("Which values are inside of the bootstrapped 95% confidence interval (select all).",
 answer(".80"),
 answer(".85"),
 answer(".90", correct = TRUE),
 answer(".95"),
 answer("1.00"),
 allow_retry = TRUE,   
  correct = random_praise(),
  incorrect = random_encouragement()
)
```




## Binomial Maths   

The are many different ways to get 233 "successes" out of 256 trials. How many exactly? Use the equation from the binomial coefficient to find out.

$${n \choose k} = \frac{n!}{k!(n-k)!}$$

NOTE, Computers have trouble keeping track of big numbers. So, to get this to work, you need to sse that

$$\frac{n!}{k!(n-k)!} = \frac{\prod_{i=(k+1)}^{i=n}{i}}{(n-k)!}$$

We can calculate the numerator in R as `prod( (k+1):n)`


```{r x, exercise=TRUE, eval = FALSE}

```


```{r manyways, echo = FALSE}
question_text("In fact there are ___ x $10^{32}$ ways to get 233 'successes' out of 256 trials (include three digits after the decimal).",
 answer("3.425", correct = TRUE),
 answer("3.42", correct = TRUE),
 answer("3.43", correct = TRUE),
 answer("3.425", correct = TRUE),
 answer("3.426", correct = TRUE),
 answer("3.424", correct = TRUE),
 allow_retry = TRUE,   
  correct = random_praise(),
  incorrect = random_encouragement()
)
```



While there are lots of ways to get 233 "successes" out of 256 trials, the probability of any one way to get this (e.g. 233 successes, followed by 23 failures. Or 23 failures followed by 233 successes…) All of these specific paths are equally probable. Find this probability for any one way of getting 233 successes of 256 trials assuming each trail has an independent probability of successes equal to 0.5.


```{r x1, exercise=TRUE, eval = FALSE}

```



```{r oneway, echo = FALSE}
question_text("The probability of any one way of getting 233 'successes' out of 256 trials,  assuming each trail has an independent probability of successes equal to 0.5.,  is ___ x $10^{-78}$  (include three digits after the decimal).",
 answer("8.636", correct = TRUE),
 answer("8.64", correct = TRUE),
 answer("8.637", correct = TRUE),
 answer("8.635", correct = TRUE),
 allow_retry = TRUE,   
  correct = random_praise(),
  incorrect = random_encouragement()
)
```


We multiply these probabilities to find the probability of seeing exactly 233 successes of 256 trials assuming each trail has an independent probability of successes equal to 0.5. Do this and confirm you are right by using the `dbinom()` function.  


```{r x2, exercise=TRUE, eval = FALSE}
<answer to q4>  * <answer to q5>   

dbinom(x = __, size = __, prob = __)
```

```{r totprob, echo = FALSE}
question_text("The probability of seeing exactly 233 successes of 256 trials assuming each trail has an independent probability of successes equal to 0.5 is ___ x $10^{-45}$ (include three digits past the decimal).",
 answer("2.958", correct = TRUE),
 answer("2.957", correct = TRUE),
 answer("2.96", correct = TRUE),
 allow_retry = TRUE,   
  correct = random_praise(),
  incorrect = random_encouragement()
)
```



## Hypothesis testing




```{r nullalt, echo=FALSE}
quiz(caption = "Null and alternative hypotheses",
question("What is the (two-tailed) null hypothesis",
  answer("Cook's pine trees are equally likely to lean towards or away from the equator", correct = TRUE),
  answer("Cook's pine trees are more likely to lean towards than away from the equator"),
  answer("Cook's pine trees are more likely to lean away from than towards the equator"),
  answer("Cook's pine trees are not equally likely to lean towards or away from the equator"),
   allow_retry = TRUE,   
    correct = random_praise(),
    incorrect = random_encouragement()
  ),
question("What is the (two-tailed) alternative hypothesis",
  answer("Cook's pine trees are equally likely to lean towards or away from the equator"),
  answer("Cook's pine trees are more likely to lean towards than away from the equator"),
  answer("Cook's pine trees are more likely to lean away from than towards the equator"),
  answer("Cook's pine trees are not equally likely to lean towards or away from the equator", correct = TRUE),
   allow_retry = TRUE,   
    correct = random_praise(),
    incorrect = random_encouragement()
  )
)
```

Now let’s make a sampling distribution under the null hypothesis, filling regions that are as or more extreme than what we saw with a different color, and marking our observations with a vertical line.



```{r nulldistbinom, exercise=TRUE, eval = FALSE}
n_trials        <- __
n_success       <- __
null_p          <- __
expected        <- __   
obs_diff_null   <- abs(__   - __)
  
lean_null_dist <- tibble(n_toward_equator = __, 
                          prob = dbinom(__),
                          as_or_more = (abs(__- __) >=  __))

ggplot(lean_null_dist, aes(x = __, y = __, fill = __))+
  geom____()+
  scale_fill_manual(values = c(__, __))+
  geom_vline(xintercept = n_success, color = "red")
```

```{r nulldistbinom-solution}
n_trials        <- 256
n_success       <- 233
null_p          <- 1/2
expected        <- null_p * n_trials  
obs_diff_null   <- abs(n_success- expected)
  
lean_null_dist <- tibble(n_toward_equator = 0:n_trials, 
                          prob = dbinom(x = 0:n_trials, size =  n_trials, prob = null_p),
                          as_or_more = (abs(n_toward_equator - expected) >=  obs_diff_null))

ggplot(lean_null_dist, aes(x = n_toward_equator, y = prob, fill = as_or_more))+
  geom_col()+
  scale_fill_manual(values = c("black", "red"))+
  geom_vline(xintercept = n_success, color = "red")
```




```{r  visualP, echo=FALSE}
question("Without calculating a p-value with math, the visual comparison of our result to the sampling distribution under the null leads you to believe __",  
         answer("That you will strongly reject the null" , correct = TRUE),
         answer("That you may or may not reject the null, as you really need the numbers to know"),
         answer("Fail to reject the null" ),
           allow_retry = TRUE,
    correct = random_praise(),
  incorrect = random_encouragement()
)
```

Let’s find an exact P-value. Sadly the learnR quiz can’t remember that you typed above, so start by copying and pasting it here.


```{r pbinomR, exercise=TRUE, eval = FALSE}
# set up
n_trials        <- __
n_success       <- __
null_p          <- __
expected        <- __  * __   
obs_diff_null   <- abs(__ - __)

# make plot  
treelean_null_dist <- tibble(n_toward_equator = 0:__, 
                          prob = dbinom(__, size = __, p = __),
                          as_or_more = abs(__ - __) >=  __)

# pvalue
treelean_null_dist %>%
  ___() %>%
  ___(p_value = ___())
```



The probability of seeing our results or something more extreme is true equals ___ x 10-45 (include two digits past the decimal)


```{r pval, echo = FALSE}
question_text("The probability of seeing our results or something more extreme is true equals ___ x $10^{-45}$ (include two digits past the decimal).",
 answer("6.56", correct = TRUE),
 answer("6.57", correct = TRUE),
 answer("6.55", correct = TRUE),
 answer("6.5", correct = TRUE),
 answer("6.6", correct = TRUE),
 allow_retry = TRUE,   
  correct = random_praise(),
  incorrect = random_encouragement()
)
```


Now let’s look at the results from the `binom.test()` function


```{r binomtest, exercise=TRUE, eval = FALSE}
binom.test(x = __, n = __, p = __)
```


From our bootstrap, we found a 95% CI between 0.875 and 0.942. Compared to this, the 95% CI from the binomial test is ___.


```{r compareboot, echo = FALSE}
question("From our bootstrap, we found a 95% CI between 0.875 and 0.942. Compared to this, the 95% CI from the binomial test is ___.",
 answer("Basically the same"),
 answer("Obviously different, but not in a biologically relevant way", correct = TRUE),
 answer("Way different, and not particularly useful"),
 allow_retry = TRUE,   
  correct = random_praise(),
  incorrect = random_encouragement()
)
```

Let's use the tidy function in the broom package to tidy this output

```{r tidy, exercise=TRUE, eval = FALSE}
library(broom)
binom.test(x = __, n = __, p = __) %>%
    tidy()
```



```{r comparep, echo = FALSE}
question("Compared to our math, the p-value from binom.test() is ___",
 answer("Basically the same", correct = TRUE),
 answer("Way different, and not particularly useful"),
 allow_retry = TRUE,   
  correct = random_praise(),
  incorrect = random_encouragement()
)
```


## Likelihood and Bayesian thinking


Plot the log-likelihood of parameter values between 0.5 and 0.999 in 0.001 increments. (hint, log = TRUE in the function you would use). This type of graph is called a log likelihood profile.


```{r loglik, exercise=TRUE, eval = FALSE}
tibble(proposed_vals = seq(0.5,.999, 0.001),
       logLik        = __(x = __, size = __, prob = __, log = TRUE)) %>%
  ggplot(aes(x = proposed_vals, y = logLik)) +
  geom_line()+
  geom_vline(xintercept = 233/256, color = "red")
```

```{r loglik-solution}
tibble(proposed_vals = seq(0.1,.999, 0.001),
       logLik        = dbinom(x = 233, size = 256, prob = proposed_vals, log = TRUE)) %>%
  ggplot(aes(x = proposed_vals, y = logLik)) +
  geom_line()+
  geom_vline(xintercept = 233/256, color = "red")
```


The maximum likelihood estimator is the parameter value that leads to the greatest log-likelihood. We could do calculus to find this (ie solve the binomial equation with our observations as function of p, and find where the first derivative is zero and the second is negative), or we could find it from this likelihood profile. Do the latter.

```{r maxlik, exercise=TRUE, eval = FALSE}
tibble(proposed_vals = seq(0.1,.999, 0.001),
       logLik        = __(x = __, size = __, prob = __, log = TRUE)) %>%
  __(__ == max(__))
```

```{r maxlik-solution}
tibble(proposed_vals = seq(0.1,.999, 0.001),
       logLik        = dbinom(x = 233, size = 256, prob = proposed_vals, log = TRUE)) %>%
  filter(logLik == max(logLik))
```


We can estimate the 95% confidence interval as values within $1−\alpha$ of the $\chi^2$ distribution divided by two `(qchisq(0.95, df = 1)/2 = 1.92)` logLiklihood units from our maximum likelihood estimator. Lets find this and compare to our previous estimates of the 95 percent confidence interval.

```{r likCI, exercise=TRUE, eval = FALSE}
tibble(proposed_vals = seq(0.1,.999, 0.001),
       logLik        = __(x = __, size = __, prob = __, log = TRUE)) %>%
  filter( (max(__) - __) < 1.92)  %>%
  summarise(lower_95_ci = __(proposed_vals), 
            upper_95_ci = max(__))
```

```{r likCI-solution}
tibble(proposed_vals = seq(0.1,.999, 0.001),
       logLik        = dbinom(x = 233, size = 256, prob = proposed_vals, log = TRUE)) %>%
  filter( max(logLik) - logLik < 1.92)  %>%
  summarise(lower_95_ci = min(proposed_vals), 
            upper_95_ci = max(proposed_vals))
```



Say that before we saw any data, we were pretty sure the true parameter was 0.5 (say we gave this a probability of 99%), but if it wasn’t we believed that all other options (from 0.001 to 0.999 in 0.001 increments) where equally likely. Let’s use Bayes’ theorem

$$P(Model|Data) = \frac{P(Data|Model) \times P(Model)}{P(Data)}$$

to find the posterior probability of these proposed parameter values. I have written this all out for you


```{r bayes, exercise=TRUE, eval = FALSE}
first_guess        <-  0.5
prior_prob1stguess <- 99/100

bayesian_math <- tibble(proposed_val = seq(.01,.999,.001),
       likelihood   = dbinom(x = 233, size = 266, prob = proposed_val)) %>%
  mutate(n_proposed = n(), 
           prior_prob  = case_when(proposed_val == 0.5 ~ prior_prob1stguess,
                                   proposed_val != 0.5 ~ (1-prior_prob1stguess ) / (n_proposed-1)),
           p_data         = sum(prior_prob * likelihood ),
           posterior_prob =  prior_prob * likelihood/ p_data) 

bayesian_math %>% 
  select(proposed_val, prior_prob, posterior_prob) %>%
  pivot_longer(cols = -1, names_to = "type", values_to = "probability")%>%
  ggplot(aes(x = proposed_val, y = probability, color = type))+
  geom_line(show.legend = FALSE)+
  facet_wrap(~type, scales = "free_y", ncol = 1)
```



Play with the value of our initial beliefs. How does this change are posterior probabilities?  

**Note** *the answer to this question is for this case only and will differ based on data and models etc.. When doing Bayesian analyses it’s important to see how robust our answers are to our priors.*

Play with the value of our prior probability this initial first guess is right. How does this change are posterior probabilities?   
**Note** *the answer to this question is for this case only and will differ based on data and models etc.. When doing Bayesian analyses it is important to see how robust our answers are to our priors.*
